{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# dummy tool\n",
    "def get_weather(location: str): \n",
    "    \"\"\"Get the weather for a given location\"\"\"\n",
    "    return f\"The weather in {location} is 70 degrees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    \"\"\"A utility to pretty print the stream.\"\"\"\n",
    "    for s in stream:\n",
    "        message = s\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model_w_tool = ChatOpenAI(model=\"gpt-4o\").bind_tools([get_weather])\n",
    "anthropic_model_w_tool = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\").bind_tools([get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative reproduction of error:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V well handled:\n",
    "- using prebuilt tool node and prebuilt react agent (which uses toolnode) / BaseTool already works perfectly because error returned neatly as ToolMessage\n",
    "  - default arg will [neatly return ToolMessage](https://github.com/langchain-ai/langgraph/blob/c0b56bf60d84ed435609c35b0691cd0305ceae78/libs/langgraph/langgraph/prebuilt/tool_node.py#L181-L185)\n",
    "\n",
    "- separated tool calls/tool message (e.g. when choosing messages to summarise - helper with trim_messages helper, but need to be aware as it's not default)\n",
    "- tool/function that is invoked outside of ToolNode that doesn't have its own error handling (specifically ToolMessage returned)\n",
    "  - Various gotchas when switching models to anthropic from openai - below show 1 example workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example workflow that could result in confusion: switching out models causing non-tool function to interrupt execution\n",
    "First, use OpenAI model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, END,START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import functools\n",
    "\n",
    "tools = [get_weather]\n",
    "tool_node = ToolNode(tools)\n",
    "# Define the graph\n",
    "memory = MemorySaver()\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state: MessagesState, model: BaseChatModel):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# calling simple .upper() method but could be a text-to-speech service for e.g.\n",
    "def function_assuming_string(state:MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(f\"Calling string method: {last_message.content.upper()}\")\n",
    "    return\n",
    "\n",
    "def function_typechecking_string(state:MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message.content, str):\n",
    "      print(f\"Calling string method: {last_message.content.upper()}\")\n",
    "    else:\n",
    "      print(f\"Calling string method: {last_message.content[0]['text'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = functools.partial(call_model,model=openai_model_w_tool)\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", openai_model)  # Using OpenAI model by default\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "workflow.add_node(\"tts\", function_assuming_string) # This will work on oai, even when there's a tool call\n",
    "workflow.add_edge(\"agent\", \"tts\")\n",
    "workflow.add_edge(\"tts\",END)\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is weather in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_WA6BBbAPmqtAQBGXjXzBVoqn)\n",
      " Call ID: call_WA6BBbAPmqtAQBGXjXzBVoqn\n",
      "  Args:\n",
      "    location: San Francisco, CA\n",
      "Calling string method: \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in San Francisco, CA is 70 degrees\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco, CA is 70 degrees Fahrenheit.\n",
      "Calling string method: THE CURRENT WEATHER IN SAN FRANCISCO, CA IS 70 DEGREES FAHRENHEIT.\n"
     ]
    }
   ],
   "source": [
    "# imagine back/forth with user, then tool call\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for chunk in graph.stream({'messages': ['what is weather in sf']}, config=config, stream_mode='values'):\n",
    "  chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, changing nothing else except to use ChatAnthropic, you'd get an error because of different response.content format\n",
    "(in practice you'd probably just change the variable name and rerun the cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_model = functools.partial(call_model,model=anthropic_model_w_tool)\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", anthropic_model)  # changed to Anthropic\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "workflow.add_node(\"tts\", function_assuming_string) # This will now not work as response.content is of type list[str | dict]\n",
    "workflow.add_edge(\"agent\", \"tts\")\n",
    "workflow.add_edge(\"tts\",END)\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is weather in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'I apologize for the confusion in my previous response. Let me fetch the current weather information for San Francisco using the available tool.', 'type': 'text'}, {'id': 'toolu_011t9Tx3xLFhBMU4pEm9oo8Q', 'input': {'location': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_011t9Tx3xLFhBMU4pEm9oo8Q)\n",
      " Call ID: toolu_011t9Tx3xLFhBMU4pEm9oo8Q\n",
      "  Args:\n",
      "    location: San Francisco\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'upper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Will usually work until there's a tool call\u001b[39;00m\n\u001b[0;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhat is weather in sf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\__init__.py:1307\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1302\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1303\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1304\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1305\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1306\u001b[0m     ):\n\u001b[1;32m-> 1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1314\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\runner.py:111\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\runner.py:273\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\executor.py:70\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\utils\\runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mfunction_assuming_string\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction_assuming_string\u001b[39m(state:MessagesState):\n\u001b[0;32m     26\u001b[0m     last_message \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling string method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlast_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'upper'"
     ]
    }
   ],
   "source": [
    "# Will usually work until there's a tool call\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for chunk in graph.stream({'messages': ['what is weather in sf']}, config=config, stream_mode='values'):\n",
    "  chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible confusion from 2 errors back to back:\n",
    "- after digging around through docs/trace and finding out that it's a Anthropic specific thing...\n",
    "- you would modify code to handle different response format\n",
    "- then rerunning with same thread id \n",
    "- But then another error will occur (the tool call) error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_model = functools.partial(call_model,model=anthropic_model_w_tool)\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", anthropic_model) \n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "workflow.add_node(\"tts\", function_typechecking_string) # This is a working implementation\n",
    "workflow.add_edge(\"agent\", \"tts\")\n",
    "workflow.add_edge(\"tts\",END)\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is weather in sf\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.6: Did not find 1 `tool_result` block(s) at the beginning of this message. Messages following `tool_use` blocks must begin with a matching number of `tool_result` blocks.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# But after fixing it, still won't work on the thread (expectedly, but confusing first time around)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhat is weather in sf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\__init__.py:1307\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1302\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1303\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1304\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1305\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1306\u001b[0m     ):\n\u001b[1;32m-> 1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1314\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\pregel\\retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\utils\\runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\Desktop\\code\\langgraph\\libs\\langgraph\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(state, model)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(state: MessagesState, model: BaseChatModel):\n\u001b[0;32m     19\u001b[0m     messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:789\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m    788\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 789\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_output(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\anthropic\\resources\\messages.py:885\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    879\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    880\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    882\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    883\u001b[0m     )\n\u001b[1;32m--> 885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\anthropic\\_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1276\u001b[0m     )\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\anthropic\\_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.poetry\\venvs\\langgraph-monorepo-jsCQxcmS-py3.12\\Lib\\site-packages\\anthropic\\_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1067\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.6: Did not find 1 `tool_result` block(s) at the beginning of this message. Messages following `tool_use` blocks must begin with a matching number of `tool_result` blocks.'}}"
     ]
    }
   ],
   "source": [
    "# But after fixing it, still won't work on the thread (expectedly, but confusing first time around)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for chunk in graph.stream({'messages': ['what is weather in sf']}, config=config, stream_mode='values'):\n",
    "  chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing thread id will work but lose state\n",
    "- Reverting to previous openai model won't work too (as the state has already been updated with tool call, without the tool message)\n",
    "- Either change thread_id (but lose state)\n",
    "- or go through the state snapshot updating process etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is weather in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"To get the weather information for San Francisco, I can use the get_weather function. I'll make the function call to retrieve that information for you.\", 'type': 'text'}, {'id': 'toolu_01TZq3Semg4qhy29zKw1JmHv', 'input': {'location': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_01TZq3Semg4qhy29zKw1JmHv)\n",
      " Call ID: toolu_01TZq3Semg4qhy29zKw1JmHv\n",
      "  Args:\n",
      "    location: San Francisco\n",
      "Calling string method: TO GET THE WEATHER INFORMATION FOR SAN FRANCISCO, I CAN USE THE GET_WEATHER FUNCTION. I'LL MAKE THE FUNCTION CALL TO RETRIEVE THAT INFORMATION FOR YOU.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "The weather in San Francisco is 70 degrees\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the information provided by the get_weather function, the current weather in San Francisco is 70 degrees Fahrenheit.\n",
      "\n",
      "Is there anything else you'd like to know about the weather in San Francisco or any other location?\n",
      "Calling string method: BASED ON THE INFORMATION PROVIDED BY THE GET_WEATHER FUNCTION, THE CURRENT WEATHER IN SAN FRANCISCO IS 70 DEGREES FAHRENHEIT.\n",
      "\n",
      "IS THERE ANYTHING ELSE YOU'D LIKE TO KNOW ABOUT THE WEATHER IN SAN FRANCISCO OR ANY OTHER LOCATION?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}} #increment thread_id and it'll work with anthropic\n",
    "for chunk in graph.stream({'messages': ['what is weather in sf']}, config=config, stream_mode='values'):\n",
    "  chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-monorepo-jsCQxcmS-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
