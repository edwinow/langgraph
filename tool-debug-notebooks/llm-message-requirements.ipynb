{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Sequence\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# dummy tool\n",
    "def get_weather(location: str): \n",
    "    \"\"\"Get the weather for a given location\"\"\"\n",
    "    return f\"The weather in {location} is 70 degrees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a dummy message sequence for testing\n",
    "def create_dummy_message_sequence(\n",
    "    sequence: list[\n",
    "        Literal[\n",
    "            \"human\",\n",
    "            \"ai_w_tool\",\n",
    "            \"ai_only\",\n",
    "            \"tool\",\n",
    "            \"system\"\n",
    "        ]\n",
    "    ],\n",
    "    dummy_content: str = \"hi\"  # default content for messages as anthropic requires content\n",
    ") -> Sequence[BaseMessage]:\n",
    "    \"\"\"\n",
    "    Create a sequence of messages for the conversation.\n",
    "    \"\"\"\n",
    "    dummy_messages = []\n",
    "    message_creators = {\n",
    "        \"human\": lambda: HumanMessage(content=dummy_content),\n",
    "        \"ai_w_tool\": lambda: AIMessage(\n",
    "            content=dummy_content,\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"args\": {\"location\": \"sf\"},\n",
    "                    \"id\": f\"tool_call_id_{len(dummy_messages)}\",\n",
    "                    \"type\": \"tool_call\",\n",
    "                }\n",
    "            ],\n",
    "        ),\n",
    "        \"ai_only\": lambda: AIMessage(content=dummy_content),\n",
    "        \"tool\": lambda: ToolMessage(\n",
    "            content=dummy_content,\n",
    "            name=\"get_weather\",\n",
    "            tool_call_id=f\"tool_call_id_{len(dummy_messages) - 1}\", # usage: Tool should always follow AI with tool.\n",
    "        ),\n",
    "        \"system\": lambda: SystemMessage(content=dummy_content),\n",
    "    }\n",
    "\n",
    "    for message_type in sequence:\n",
    "        dummy_messages.append(message_creators[message_type]())\n",
    "\n",
    "    dummy_messages = [message_creators[message_type]() for message_type in sequence]\n",
    "    return dummy_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = ChatOpenAI(model=\"gpt-4o\") \n",
    "openai_model_w_tool = openai_model.bind_tools([get_weather])\n",
    "anthropic_model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "anthropic_model_w_tool = anthropic_model.bind_tools([get_weather])\n",
    "\n",
    "def pretty_invoke(model: BaseChatModel, messages: Sequence[BaseMessage]): \n",
    "  print(f\"### Model: {model.get_name()} ###\")\n",
    "  try:\n",
    "    print(f'✅: {model.invoke(messages).content}\\n')\n",
    "  except Exception as e:\n",
    "    print(f'❌: {e}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to error out (and a general pattern where Anthropic much stricter than oai with messages)\n",
    "Easy if it breaks immediately, but sometimes swapping models out works for a few runs, then breaks for any of the reasons below. Hard to debug because because the changes were made some time ago. \n",
    "- e.g. sliding windows of summarisation where most times it works, but then suddenly doesn't.\n",
    "  - different permutations of whether and when a tool is called, whether it was renamed or not\n",
    "- separately, when a function is run as a node in the same step as a tool call, works most of the time, but failed once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty messages not handled by anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: ChatOpenAI ###\n",
      "✅: Hello! How can I assist you today?\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: all messages must have non-empty content except for the optional final assistant message'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_without_content =  create_dummy_message_sequence([\"human\", \"ai_only\", \"human\"], dummy_content=\"\")\n",
    "pretty_invoke(openai_model, message_without_content)\n",
    "pretty_invoke(anthropic_model, message_without_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatAnthropic needs every tool in message history to be bound, even if no longer using it. Relevant when: \n",
    "- using ChatAnthropic as a node/tool, passing history (e.g. to summarise)\n",
    "- or when making changes to the tool/tool name, and re-running on same thread where message history have tool calls/tool messages that are outdated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: ChatOpenAI ###\n",
      "❌: Error code: 400 - {'error': {'message': \"Invalid parameter: 'tool_call_id' of 'tool_call_id_2' not found in 'tool_calls' of previous message.\", 'type': 'invalid_request_error', 'param': 'messages.[1].tool_call_id', 'code': None}}\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': \"messages.1: unexpected `tool_use_id`s found in `tool_result` blocks: {'tool_call_id_2'}\"}}\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': \"messages.1: unexpected `tool_use_id`s found in `tool_result` blocks: {'tool_call_id_2'}\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages_with_tool_call =  create_dummy_message_sequence([\"ai_w_tool\", \"tool\", \"human\"])\n",
    "pretty_invoke(openai_model, messages_with_tool_call)\n",
    "pretty_invoke(anthropic_model, messages_with_tool_call) \n",
    "pretty_invoke(anthropic_model_w_tool, messages_with_tool_call) # model with bound tool works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must end with human message when using tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: ChatOpenAI ###\n",
      "✅: Hello! How can I assist you today?\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "✅:  there! How can I assist you today?\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your API request included an `assistant` message in the final position, which would pre-fill the `assistant` response. When using tools, pre-filling the `assistant` response is not supported.'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages_ending_with_ai =  create_dummy_message_sequence([\"human\", \"ai_only\"])\n",
    "pretty_invoke(openai_model, messages_ending_with_ai)\n",
    "pretty_invoke(anthropic_model, messages_ending_with_ai) \n",
    "pretty_invoke(anthropic_model_w_tool, messages_ending_with_ai) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must have system message at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: ChatOpenAI ###\n",
      "✅: Hello! How can I assist you today?\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: System message must be at beginning of message list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages_with_system_message_inserted =  create_dummy_message_sequence([\"human\", \"ai_only\", \"system\", \"ai_only\", \"human\"])\n",
    "pretty_invoke(openai_model, messages_with_system_message_inserted)\n",
    "pretty_invoke(anthropic_model, messages_with_system_message_inserted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool related errors (expected)\n",
    "- ToolMessage must be after tool call and vice versa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: ChatOpenAI ###\n",
      "❌: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: tool_call_id_2\", 'type': 'invalid_request_error', 'param': 'messages.[1].role', 'code': None}}\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.1: Did not find 1 `tool_result` block(s) at the beginning of this message. Messages following `tool_use` blocks must begin with a matching number of `tool_result` blocks.'}}\n",
      "\n",
      "### Model: ChatOpenAI ###\n",
      "❌: Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[0].role', 'code': None}}\n",
      "\n",
      "### Model: ChatAnthropic ###\n",
      "❌: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: `tool_result` block(s) provided when previous message does not contain any `tool_use` blocks'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tool_call_without_tool_message =  create_dummy_message_sequence(['ai_w_tool', 'human'])\n",
    "pretty_invoke(openai_model, tool_call_without_tool_message)\n",
    "pretty_invoke(anthropic_model, tool_call_without_tool_message) \n",
    "\n",
    "tool_message_without_tool_call =  create_dummy_message_sequence(['tool', 'human'])\n",
    "pretty_invoke(openai_model, tool_message_without_tool_call)\n",
    "pretty_invoke(anthropic_model, tool_message_without_tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temp quick win in docs:\n",
    "- add in the error codes so show up in search\n",
    "- highlight that it's important to keep tool message/tool call paired\n",
    "- maybe highlighting differences for main few models?\n",
    "\n",
    "Maybe/prob not:\n",
    "- Default grouping of tool call/tool message under the hood as sensible default? e.g. when removing/trimming/summarising\n",
    "- Changing error message to enrich model error code ('update with toolmessage, or remove last message in state snapshot')\n",
    "- Interface at Chat Model level? e.g. o1 has no system message allowed/more and more changes in future, leave it to models to handle\n",
    "- Checks on... graph compilation/runtime?\n",
    "- Auto filling of ToolMessage/error handling in prod?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-monorepo-jsCQxcmS-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
